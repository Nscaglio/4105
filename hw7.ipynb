{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMGMoExiM4CqGwG430997Qo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nscaglio/4105/blob/main/hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UOWzlKdo6B7v"
      },
      "outputs": [],
      "source": [
        "# initialize libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.A\n"
      ],
      "metadata": {
        "id": "zZffr3ew6XQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformation to normalize the CIFAR-10 data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training and test datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoader for training and testing\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # Input: 3x32x32, Output: 32x32x32\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Pooling layer with 2x2 kernel\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # Output: 64x16x16\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Flattened size after pooling (64 * 8 * 8 = 4096)\n",
        "        self.fc2 = nn.Linear(512, 10)  # 10 classes for CIFAR-10\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first convolution -> ReLU -> Max Pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Apply Conv1 -> ReLU -> Pooling\n",
        "\n",
        "        # Apply second convolution -> ReLU -> Max Pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Apply Conv2 -> ReLU -> Pooling\n",
        "\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = torch.flatten(x, 1)  # Flatten: (batch_size, 64 * 8 * 8)\n",
        "\n",
        "\n",
        "        # Apply fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # Apply FC1 -> ReLU\n",
        "        x = self.fc2(x)  # Output layer (no activation, softmax applied later)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = CNNModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BXr2DvP6Vbv",
        "outputId": "70e90590-ff4a-48f9-8667-563ea3b62e18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Training the model\n",
        "epochs = 200\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "start_time = time.time()  # Track the start time\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    test_accuracy_history.append(test_accuracy)\n",
        "\n",
        "    # Print statistics\n",
        "    if (epoch + 1) % 20 == 0:  # Print every 20 epochs\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Record training time\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
        "\n",
        "# Final test accuracy\n",
        "print(f\"\\nFinal Test Accuracy: {test_accuracy_history[-1]:.2f}%\")"
      ],
      "metadata": {
        "id": "dX6akMap6Y24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4640bc-3745-4950-f724-7a618becd5a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Loss: 0.0343, Train Accuracy: 98.84%, Test Accuracy: 72.77%\n",
            "Epoch [40/200], Loss: 0.0206, Train Accuracy: 99.35%, Test Accuracy: 72.33%\n",
            "Epoch [60/200], Loss: 0.0248, Train Accuracy: 99.27%, Test Accuracy: 72.22%\n",
            "Epoch [80/200], Loss: 0.0127, Train Accuracy: 99.62%, Test Accuracy: 72.68%\n",
            "Epoch [100/200], Loss: 0.0115, Train Accuracy: 99.66%, Test Accuracy: 72.85%\n",
            "Epoch [120/200], Loss: 0.0140, Train Accuracy: 99.67%, Test Accuracy: 72.15%\n",
            "Epoch [140/200], Loss: 0.0088, Train Accuracy: 99.78%, Test Accuracy: 72.22%\n",
            "Epoch [160/200], Loss: 0.0127, Train Accuracy: 99.73%, Test Accuracy: 72.03%\n",
            "Epoch [180/200], Loss: 0.0172, Train Accuracy: 99.68%, Test Accuracy: 71.63%\n",
            "Epoch [200/200], Loss: 0.0116, Train Accuracy: 99.79%, Test Accuracy: 71.59%\n",
            "\n",
            "Training Time: 3124.93 seconds\n",
            "\n",
            "Final Test Accuracy: 71.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.B"
      ],
      "metadata": {
        "id": "ZnhnXjMz6eRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class ExtendedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExtendedCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers with BatchNorm and Pooling\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Fully connected layers with reduced input size\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 1024)  # Reduced size after pooling\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)  # CIFAR-10 has 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through convolutional layers with BatchNorm and Pooling\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 64 * 4 * 4)\n",
        "\n",
        "        # Forward pass through fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # Output layer\n",
        "\n",
        "        return x\n",
        "\n",
        "# Test the network with a random input\n",
        "model = ExtendedCNN()\n",
        "# Set up the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set up the number of epochs\n",
        "epochs = 200\n",
        "\n",
        "# For tracking loss, accuracy, and training time\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "start_time = time.time()  # Track the start time\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    test_accuracy_history.append(test_accuracy)\n",
        "\n",
        "    # Print statistics every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:  # Print every 20 epochs\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Record the total training time\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
        "\n",
        "# Final test accuracy\n",
        "print(f\"\\nFinal Test Accuracy: {test_accuracy_history[-1]:.2f}%\")"
      ],
      "metadata": {
        "id": "ejEWxS0V6fzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff1c6a3-e9a1-4c5d-f006-e935aeefdff7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Loss: 0.0651, Train Accuracy: 97.73%, Test Accuracy: 76.35%\n",
            "Epoch [40/200], Loss: 0.0344, Train Accuracy: 98.91%, Test Accuracy: 76.24%\n",
            "Epoch [60/200], Loss: 0.0167, Train Accuracy: 99.46%, Test Accuracy: 76.19%\n",
            "Epoch [80/200], Loss: 0.0189, Train Accuracy: 99.39%, Test Accuracy: 76.42%\n",
            "Epoch [100/200], Loss: 0.0166, Train Accuracy: 99.47%, Test Accuracy: 75.01%\n",
            "Epoch [120/200], Loss: 0.0214, Train Accuracy: 99.39%, Test Accuracy: 75.91%\n",
            "Epoch [140/200], Loss: 0.0114, Train Accuracy: 99.65%, Test Accuracy: 75.83%\n",
            "Epoch [160/200], Loss: 0.0128, Train Accuracy: 99.63%, Test Accuracy: 76.24%\n",
            "Epoch [180/200], Loss: 0.0093, Train Accuracy: 99.73%, Test Accuracy: 75.81%\n",
            "Epoch [200/200], Loss: 0.0196, Train Accuracy: 99.49%, Test Accuracy: 76.19%\n",
            "\n",
            "Training Time: 3144.85 seconds\n",
            "\n",
            "Final Test Accuracy: 76.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "K_MwlgzC6qg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        return F.relu(out)\n",
        "\n",
        "# Define ResNet10 Architecture\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet10, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # 5 Residual Blocks with reduced depth and stride\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlock(16, 16, stride=1),\n",
        "            ResidualBlock(16, 32, stride=2),\n",
        "            ResidualBlock(32, 64, stride=2),\n",
        "            ResidualBlock(64, 128, stride=2),\n",
        "            ResidualBlock(128, 256, stride=2)\n",
        "        )\n",
        "\n",
        "        # Calculate the size of the feature map after all convolutional layers\n",
        "        self._calculate_conv_output_size()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(self.conv_output_size, 10)  # Output layer with 10 classes\n",
        "\n",
        "    def _calculate_conv_output_size(self):\n",
        "        # Create a dummy input tensor of shape (1, 3, 32, 32) to simulate a batch of images\n",
        "        dummy_input = torch.zeros(1, 3, 32, 32)\n",
        "        dummy_output = self._forward_conv(dummy_input)\n",
        "        self.conv_output_size = dummy_output.numel()  # This gives the total number of elements in the output tensor\n",
        "\n",
        "    def _forward_conv(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.res_blocks(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.res_blocks(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, channels * height * width)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Test the architecture with a random input\n",
        "model = ResNet10()\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set up the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Set up the number of epochs\n",
        "epochs = 200\n",
        "\n",
        "# For tracking loss, accuracy, and training time\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "# Assuming you already have trainloader and testloader for CIFAR-10 data\n",
        "start_time = time.time()  # Track the start time\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    # Evaluate on the test dataset\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    test_accuracy_history.append(test_accuracy)\n",
        "\n",
        "    # Print statistics every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:  # Print every 20 epochs\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Record the total training time\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
        "\n",
        "# Final test accuracy\n",
        "print(f\"\\nFinal Test Accuracy: {test_accuracy_history[-1]:.2f}%\")"
      ],
      "metadata": {
        "id": "1bNVfgIT6rii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16635a4e-3da6-4f98-ceb8-87fa4c123e16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Loss: 0.0423, Train Accuracy: 98.55%, Test Accuracy: 77.22%\n",
            "Epoch [40/200], Loss: 0.0204, Train Accuracy: 99.33%, Test Accuracy: 77.94%\n",
            "Epoch [60/200], Loss: 0.0144, Train Accuracy: 99.49%, Test Accuracy: 78.03%\n",
            "Epoch [80/200], Loss: 0.0130, Train Accuracy: 99.58%, Test Accuracy: 77.73%\n",
            "Epoch [100/200], Loss: 0.0156, Train Accuracy: 99.47%, Test Accuracy: 77.35%\n",
            "Epoch [120/200], Loss: 0.0059, Train Accuracy: 99.82%, Test Accuracy: 78.14%\n",
            "Epoch [140/200], Loss: 0.0140, Train Accuracy: 99.54%, Test Accuracy: 77.87%\n",
            "Epoch [160/200], Loss: 0.0101, Train Accuracy: 99.69%, Test Accuracy: 78.38%\n",
            "Epoch [180/200], Loss: 0.0056, Train Accuracy: 99.78%, Test Accuracy: 78.27%\n",
            "Epoch [200/200], Loss: 0.0083, Train Accuracy: 99.73%, Test Accuracy: 78.70%\n",
            "\n",
            "Training Time: 3532.98 seconds\n",
            "\n",
            "Final Test Accuracy: 78.70%\n"
          ]
        }
      ]
    }
  ]
}